{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import explainer.rule_pattern_miner as rlm\n",
    "import explainer.DT_rules as dtr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = os.getcwd()\n",
    "sys.path.append(os.path.join(here,\"../../\"))\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_feature_raw_value(fid,fval,featur_names,raw_min_max,ntype=\"min_max\"):\n",
    "    fn = featur_names[fid]\n",
    "    if ntype == \"min_max\":\n",
    "        if fn in raw_min_max.columns:\n",
    "            mx = raw_min_max.loc[:,fn].max()\n",
    "            mi = raw_min_max.loc[:,fn].min()\n",
    "            return fval*(mx-mi)+mi\n",
    "        return fval\n",
    "    else:\n",
    "        raise TypeError(\"Not yet supported type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the data into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "dataset = MoleculeNet(root='data/MoleculeNet', name='Tox21')\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transform SMILES to RDKit descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None  # Handle invalid SMILES input\n",
    "\n",
    "    descriptor_name = []; value_list = []\n",
    "    for name, descriptor_function in Descriptors.descList:\n",
    "        value = descriptor_function(mol)\n",
    "        value_list.append(value)\n",
    "        descriptor_name.append(name)\n",
    "\n",
    "    return value_list, descriptor_name\n",
    "\n",
    "def smiles_to_rdkit(dataset):\n",
    "    rdk_features = []\n",
    "    for i in range(len(dataset)):\n",
    "        smiles = dataset[i].smiles\n",
    "        features, descriptors = calculate_all_descriptors(smiles)\n",
    "        rdk_features.append(features)\n",
    "\n",
    "    return torch.tensor(rdk_features, dtype=torch.float32), descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Divide the data into training validatiton and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:int(len(dataset) * 0.7)]\n",
    "val_dataset = dataset[int(len(dataset) * 0.7):int(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.8):]\n",
    "\n",
    "## generate rdk descriptors from smiles representation of molecules\n",
    "dataset_rdk, descriptors = smiles_to_rdkit(dataset)\n",
    "## remove descriptors with nan values\n",
    "descriptors = [descriptors[i] for i in range(len(descriptors)) if ~torch.any(dataset_rdk.isnan(), dim=0)[i]]\n",
    "dataset_rdk = dataset_rdk[:,~torch.any(dataset_rdk.isnan(), dim=0)]\n",
    "dataset_rdk = (dataset_rdk - dataset_rdk.mean(axis=0))/dataset_rdk.std(axis=0) ## normalize\n",
    "descriptors = [descriptors[i] for i in range(len(descriptors)) if ~torch.any(dataset_rdk.isnan(), dim=0)[i]]\n",
    "dataset_rdk = dataset_rdk[:,~torch.any(dataset_rdk.isnan(), dim=0)]\n",
    "\n",
    "train_dataset_rdk = dataset_rdk[:int(len(dataset_rdk) * 0.7)]\n",
    "val_dataset_rdk = dataset_rdk[int(len(dataset_rdk) * 0.7):int(len(dataset_rdk) * 0.8)]\n",
    "test_dataset_rdk = dataset_rdk[int(len(dataset_rdk) * 0.8):]\n",
    "\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "## task weights for training\n",
    "mask = 1-torch.isnan(train_dataset.y).type(torch.float32)\n",
    "task_weight = 1 / torch.mean(mask, axis = 0)\n",
    "label_weight = torch.sum(train_dataset.y == 0., axis = 0) / torch.sum(train_dataset.y == 1., axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64; learning_rate=0.001; num_epoch=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MLP model on RDK features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "        self.activation_fn_last = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.activation_fn_last(self.lin(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class GNNtraining(object):\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 learning_rate=0.001, \n",
    "                 num_epoch=200,\n",
    "                 use_cuda=False):\n",
    "        \n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epoch = num_epoch\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        if use_cuda:\n",
    "            self.model.cuda()\n",
    "        \n",
    "    def training(self, train_loader, val_loader, task_weight, label_weight):     \n",
    "        parameters = set(self.model.parameters())\n",
    "        optimizer = optim.Adam(parameters, lr=self.learning_rate, eps=1e-3)\n",
    "\n",
    "        for epoch in range(self.num_epoch):\n",
    "            for data in train_loader:\n",
    "                y_batch = torch.nan_to_num(data.y, nan=0.0) # nan to 0.0\n",
    "                \n",
    "                task_weight_batch = ~data.y.isnan()*task_weight # weight each task according to the number of valid labels\n",
    "                label_weight_batch = y_batch * label_weight; label_weight_batch[label_weight_batch==0.0] = 1.0 # weight each label according to the number of positive labels\n",
    "                w_batch = task_weight_batch * label_weight_batch\n",
    "                if self.use_cuda:\n",
    "                    data = data.cuda(); y_batch = y_batch.cuda(); w_batch = w_batch.cuda()\n",
    "                criterion = nn.BCELoss(weight=w_batch)\n",
    "                optimizer.zero_grad()\n",
    "                self.model.train()\n",
    "                # calculate the training loss\n",
    "                output = self.model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            train_bce = loss.detach()\n",
    "            train_acc = self.evaluation(train_loader)\n",
    "            val_acc = self.evaluation(val_loader)\n",
    "            print('>>> Epoch {:5d}/{:5d} | train_bce={:.5f} | train_acc={:.5f} | val_acc={:.5f}'.format(epoch, self.num_epoch, train_bce, train_acc, val_acc))\n",
    "                \n",
    "    def evaluation(self, loader):\n",
    "        self.model.eval()\n",
    "        correct = 0; total = 0\n",
    "        for data in loader:\n",
    "            if self.use_cuda:\n",
    "                data = data.cuda()\n",
    "            output = self.model(data.x.to(torch.float32), data.edge_index, data.batch)\n",
    "            pred = (output > 0.5).to(torch.float32)\n",
    "            correct += int((pred == data.y).sum())\n",
    "            total += int((~data.y.isnan()).sum())\n",
    "\n",
    "        return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader as GDataLoader\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "train_loader = GDataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = GDataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "gnn = GNN(hidden_channels=64)\n",
    "gnn.load_state_dict(torch.load('gnn_models/gnn_42.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "train_loader_visualization = GDataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "for train_data in train_loader_visualization:\n",
    "    break\n",
    "for val_data in val_loader:\n",
    "    break\n",
    "train_loader_rdk_visualization = DataLoader(TensorDataset(train_dataset_rdk, train_dataset.y), batch_size=len(train_dataset_rdk), shuffle=False)\n",
    "for train_data_x, train_data_y in train_loader_rdk_visualization:\n",
    "    break\n",
    "\n",
    "y_pred_s_gnn = gnn(train_data.x.to(torch.float32), train_data.edge_index, train_data.batch).detach().numpy()\n",
    "\n",
    "y_pred_test_gnn = gnn(val_data.x.to(torch.float32), val_data.edge_index, val_data.batch).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Task AR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11 Task AR; select hyper-parameters of AMORE and DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_task = 0\n",
    "\n",
    "y_true = train_data.y.numpy()[:,idx_task:idx_task+1].reshape(-1); idx = ~np.isnan(y_true)\n",
    "y_pred_s = y_pred_s_gnn[:,idx_task:idx_task+1].reshape(-1)[idx]\n",
    "y_true = y_true[idx].astype(int)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_s)\n",
    "th_id = np.argmax(tpr - fpr); y_thd = thresholds[th_id]\n",
    "\n",
    "fids = [i for i in range(len(descriptors))]\n",
    "feature_types = []\n",
    "for i in range(len(descriptors)):\n",
    "    c = descriptors[i]\n",
    "    if np.dtype(train_data_x.numpy()[idx][:,i][0])!=np.uint8:\n",
    "        feature_types.append(str(np.dtype(train_data_x.numpy()[idx][:,i][0])))\n",
    "    else:\n",
    "        feature_types.append(\"cat\")\n",
    "    # print(c,np.dtype(train_data_x.numpy()[idx][:,i][0]),feature_types[-1])\n",
    "\n",
    "y_true_test = val_data.y.numpy()[:,idx_task:idx_task+1].reshape(-1); idx_test = ~np.isnan(y_true_test)\n",
    "y_pred_test = y_pred_test_gnn[:,idx_task:idx_task+1].reshape(-1)[idx_test]\n",
    "y_true_test = y_true_test[idx_test].astype(int)\n",
    "\n",
    "print('Task {}: total positive: {:}; total predictived positive:{:}; recall:{:.5f}; precision:{:.5f}; auroc: {:.5f}; test auroc:  {:.5f}'.format(idx_task, sum(y_true), sum(y_pred_s>y_thd), recall_score(y_true, y_pred_s>y_thd), precision_score(y_true, y_pred_s>y_thd), roc_auc_score(y_true, y_pred_s), roc_auc_score(y_true_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set \"grid_search = True\" to do a grid search for hyperprameters\n",
    "\n",
    "grid_search = True\n",
    "\n",
    "if grid_search:\n",
    "    ng_range = np.arange(2,21)\n",
    "    bin_strategies = [\"uniform\",\"kmeans\"]\n",
    "    support_range = np.arange(100,1000,100)\n",
    "    confidence_lower_bound = 0.8\n",
    "    max_depth=2\n",
    "    top_K=3\n",
    "\n",
    "\n",
    "    best_rule_set,best_configs,config_metric_records = rlm.param_grid_search_for_amore(bin_strategies,ng_range,support_range,train_data_x.numpy()[idx],fids,target_indices=y_pred_s>y_thd,y=y_true,c=1,confidence_lower_bound = confidence_lower_bound,\n",
    "                                                                                        max_depth=max_depth,top_K=top_K,sort_by=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set \"grid_search = True\" to do a grid search for hyperprameters\n",
    "\n",
    "grid_search = True\n",
    "\n",
    "if grid_search:\n",
    "    criteria = [\"gini\", \"entropy\", \"log_loss\"]; c=1.\n",
    "    w = (y_true==c).sum()/y_true.shape[0]\n",
    "    # class_weight_options = [{0:0.5,1:0.5},{0:1./(1.-w),1:1./w}]\n",
    "    class_weight_options = [{0:0.5,1:0.5},'balanced']\n",
    "    support_range = np.arange(100,1000,100)\n",
    "    confidence_lower_bound = 0.\n",
    "    max_depth=2\n",
    "    DT_best_rule_set, DT_best_configs, DT_config_metric_records = dtr.param_grid_search_for_DT(criteria,support_range,weight_options=class_weight_options,X=train_data_x.numpy()[idx],y=y_true,target_indices=y_pred_s>y_thd,c=1,max_depth=max_depth,feature_names=descriptors,confidence_lower_bound=confidence_lower_bound,seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 Task AR; fitness and confidence with different minimum support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_lower_bound_dt = 0.0\n",
    "confidence_lower_bound_amore=0.8\n",
    "\n",
    "cf_mtx = np.vstack([config_metric_records[key]['top_confidence_records'] for key in config_metric_records.keys()])\n",
    "ft_mtx = np.vstack([config_metric_records[key]['top_fitness_records'] for key in config_metric_records.keys()])\n",
    "as_mtx = np.vstack([config_metric_records[key]['actual_support'] for key in config_metric_records.keys()])\n",
    "DT_cf_mtx = np.vstack([DT_config_metric_records[key]['top_confidence_records'] for key in DT_config_metric_records.keys()])\n",
    "DT_ft_mtx = np.vstack([DT_config_metric_records[key]['top_fitness_records'] for key in DT_config_metric_records.keys()])\n",
    "DT_as_mtx = np.vstack([DT_config_metric_records[key]['actual_support'] for key in DT_config_metric_records.keys()])\n",
    "best_cfs,best_fts,best_ass=[],[],[]\n",
    "DT_best_cfs,DT_best_fts,DT_best_ass=[],[],[]\n",
    "ft_mtx_cp = ft_mtx.copy()\n",
    "DT_ft_mtx_cp = DT_ft_mtx.copy()\n",
    "ft_mtx_cp[cf_mtx<confidence_lower_bound_amore]=0\n",
    "DT_ft_mtx_cp[DT_cf_mtx<confidence_lower_bound_dt]=0.\n",
    "for s in range(cf_mtx.shape[1]):\n",
    "    cid = np.argmax(ft_mtx_cp[:,s])\n",
    "    bc = cf_mtx[cid,s]\n",
    "    if bc >= confidence_lower_bound_amore:\n",
    "        best_cfs.append(bc)\n",
    "        best_fts.append(ft_mtx[cid,s])\n",
    "        best_ass.append(as_mtx[cid,s])\n",
    "    else:\n",
    "        cid = np.argmax(ft_mtx[:,s])\n",
    "        bc = cf_mtx[cid,s]\n",
    "        best_cfs.append(bc)\n",
    "        best_fts.append(ft_mtx[cid,s])\n",
    "        best_ass.append(as_mtx[cid,s])\n",
    "    cid = np.argmax(DT_ft_mtx_cp[:,s])\n",
    "    bc = DT_cf_mtx[cid,s]\n",
    "    if bc >= confidence_lower_bound_dt:\n",
    "        DT_best_cfs.append(bc)\n",
    "        DT_best_fts.append(DT_ft_mtx[cid,s])\n",
    "        DT_best_ass.append(DT_as_mtx[cid,s])\n",
    "    else:\n",
    "        cid = np.argmax(DT_ft_mtx[:,s])\n",
    "        bc = DT_cf_mtx[cid,s]\n",
    "        DT_best_cfs.append(bc)\n",
    "        DT_best_fts.append(DT_ft_mtx[cid,s])\n",
    "        DT_best_ass.append(DT_as_mtx[cid,s])\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(5,4))\n",
    "color1 = '#377EB8'  # Blue\n",
    "color2 = '#E41A1C'  # Red\n",
    "color3 = '#4DAF4A'  # green\n",
    "plt.plot(support_range,best_cfs,'-o',color=color1,markersize=4)\n",
    "plt.plot(support_range,best_fts,'--o',color=color1,markersize=4)\n",
    "plt.plot(support_range,DT_best_cfs,'-o',color=color2,markersize=4)\n",
    "plt.plot(support_range,DT_best_fts,'--o',color=color2,markersize=4)\n",
    "plt.xlim(100,900)\n",
    "plt.ylim(0.,1.)\n",
    "# Creating custom lines for the color legend\n",
    "custom_lines_color = [Line2D([0], [0], color=color1, lw=4),\n",
    "                      Line2D([0], [0], color=color2, lw=4)]\n",
    "# Creating custom lines for the line style legend\n",
    "custom_lines_style = [Line2D([0], [0], color='grey', lw=2, linestyle='-'),\n",
    "                      Line2D([0], [0], color='grey', lw=2, linestyle='--')]\n",
    "\n",
    "plt.xlabel('Specified minimum support')\n",
    "# plt.savefig('plot/compare_DT_AR.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 Task AR; Rules extracted from AMORE and DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### search rules for target pattern: pred_y > y_thd  ###\n",
    "### we set the hyperparameters obtaind by above grid search step ###\n",
    "\n",
    "min_support=best_configs['min_support']\n",
    "bin_strategy=best_configs['bin_strategy']\n",
    "num_grids=best_configs['num_grids']\n",
    "max_depth=2\n",
    "top_K=3\n",
    "\n",
    "y_rule_candidates = rlm.gen_rule_list_for_one_target(train_data_x.numpy()[idx],fids,y_pred_s>y_thd,y=y_true,c=1,sort_by=\"fitness\",\n",
    "                                                    min_support=min_support,num_grids=num_grids,max_depth=max_depth,top_K=top_K,\n",
    "                                                    local_x=None,feature_types=feature_types,bin_strategy=bin_strategy,\n",
    "                                                    verbose=False)\n",
    "\n",
    "for i, rules in enumerate(y_rule_candidates):   \n",
    "    rules[\"rules\"] = rlm.replace_feature_names(rules[\"rules\"],descriptors)\n",
    "    y_rule_candidates[i] = rules\n",
    "y_rule_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain rules for target pattern: pred_y > y_thd from a DecisionTreeClassifier ###\n",
    "### We set the hyperparameters obtaind by above grid search step ###\n",
    "criterion = DT_best_configs['criterion']\n",
    "class_weight = DT_best_configs['class_weight']\n",
    "min_support = DT_best_configs['min_support']\n",
    "\n",
    "input_feature_names =descriptors\n",
    "treemodel = DecisionTreeClassifier(max_depth=max_depth,min_samples_leaf=min_support,criterion=criterion,random_state=seed,class_weight=class_weight)\n",
    "treemodel.fit(train_data_x.numpy()[idx],y_pred_s>y_thd)\n",
    "rule_list, rule_value_list, rule_metric_list, new_lines = dtr.obtain_rule_lists_from_DT(treemodel,train_data_x.numpy()[idx],y_true,y_pred_s>y_thd,np.arange(train_data_x.numpy()[idx].shape[-1]),descriptors,c=1)\n",
    "print(export_text(treemodel))\n",
    "\n",
    "## display rules extracted by DT classifier\n",
    "dtr.display_rules_from_DT(rule_list,rule_metric_list,input_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Task ER-LBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21 Task ER-LBD; select hyper-parameters of AMORE and DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_task = 4\n",
    "\n",
    "y_true = train_data.y.numpy()[:,idx_task:idx_task+1].reshape(-1); idx = ~np.isnan(y_true)\n",
    "y_pred_s = y_pred_s_gnn[:,idx_task:idx_task+1].reshape(-1)[idx]\n",
    "y_true = y_true[idx].astype(int)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_s)\n",
    "th_id = np.argmax(tpr - fpr); y_thd = thresholds[th_id]\n",
    "\n",
    "fids = [i for i in range(len(descriptors))]\n",
    "feature_types = []\n",
    "for i in range(len(descriptors)):\n",
    "    c = descriptors[i]\n",
    "    if np.dtype(train_data_x.numpy()[idx][:,i][0])!=np.uint8:\n",
    "        feature_types.append(str(np.dtype(train_data_x.numpy()[idx][:,i][0])))\n",
    "    else:\n",
    "        feature_types.append(\"cat\")\n",
    "    # print(c,np.dtype(train_data_x.numpy()[idx][:,i][0]),feature_types[-1])\n",
    "\n",
    "y_true_test = val_data.y.numpy()[:,idx_task:idx_task+1].reshape(-1); idx_test = ~np.isnan(y_true_test)\n",
    "y_pred_test = y_pred_test_gnn[:,idx_task:idx_task+1].reshape(-1)[idx_test]\n",
    "y_true_test = y_true_test[idx_test].astype(int)\n",
    "\n",
    "print('Task {}: total positive: {:}; total predictived positive:{:}; recall:{:.5f}; precision:{:.5f}; auroc: {:.5f}; test auroc:  {:.5f}'.format(idx_task, sum(y_true), sum(y_pred_s>y_thd), recall_score(y_true, y_pred_s>y_thd), precision_score(y_true, y_pred_s>y_thd), roc_auc_score(y_true, y_pred_s), roc_auc_score(y_true_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set \"grid_search = True\" to do a grid search for hyperprameters\n",
    "\n",
    "grid_search = True\n",
    "\n",
    "if grid_search:\n",
    "    ng_range = np.arange(2,21)\n",
    "    bin_strategies = [\"uniform\",\"kmeans\"]\n",
    "    support_range = np.arange(100,2000,200)\n",
    "    confidence_lower_bound = 0.8\n",
    "    max_depth=2\n",
    "    top_K=3\n",
    "\n",
    "\n",
    "    best_rule_set,best_configs,config_metric_records = rlm.param_grid_search_for_amore(bin_strategies,ng_range,support_range,train_data_x.numpy()[idx],fids,target_indices=y_pred_s>y_thd,y=y_true,c=1,confidence_lower_bound = confidence_lower_bound,\n",
    "                                                                                        max_depth=max_depth,top_K=top_K,sort_by=\"fitness\")\n",
    "\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set \"grid_search = True\" to do a grid search for hyperprameters\n",
    "\n",
    "grid_search = True\n",
    "\n",
    "if grid_search:\n",
    "    criteria = [\"gini\", \"entropy\", \"log_loss\"]; c=1.\n",
    "    w = (y_true==c).sum()/y_true.shape[0]\n",
    "    class_weight_options = [{0:0.5,1:0.5},'balanced']\n",
    "    support_range = np.arange(100,2000,200)\n",
    "    confidence_lower_bound = 0.\n",
    "    max_depth=2\n",
    "    DT_best_rule_set, DT_best_configs, DT_config_metric_records = dtr.param_grid_search_for_DT(criteria,support_range,weight_options=class_weight_options,X=train_data_x.numpy()[idx],y=y_true,target_indices=y_pred_s>y_thd,c=1,max_depth=max_depth,feature_names=descriptors,confidence_lower_bound=confidence_lower_bound,seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.22 Task ER-LBD; fitness and confidence with different minimum support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_lower_bound_dt = 0.0\n",
    "confidence_lower_bound_amore=0.8\n",
    "\n",
    "\n",
    "cf_mtx = np.vstack([config_metric_records[key]['top_confidence_records'] for key in config_metric_records.keys()])\n",
    "ft_mtx = np.vstack([config_metric_records[key]['top_fitness_records'] for key in config_metric_records.keys()])\n",
    "as_mtx = np.vstack([config_metric_records[key]['actual_support'] for key in config_metric_records.keys()])\n",
    "DT_cf_mtx = np.vstack([DT_config_metric_records[key]['top_confidence_records'] for key in DT_config_metric_records.keys()])\n",
    "DT_ft_mtx = np.vstack([DT_config_metric_records[key]['top_fitness_records'] for key in DT_config_metric_records.keys()])\n",
    "DT_as_mtx = np.vstack([DT_config_metric_records[key]['actual_support'] for key in DT_config_metric_records.keys()])\n",
    "best_cfs,best_fts,best_ass=[],[],[]\n",
    "DT_best_cfs,DT_best_fts,DT_best_ass=[],[],[]\n",
    "ft_mtx_cp = ft_mtx.copy()\n",
    "DT_ft_mtx_cp = DT_ft_mtx.copy()\n",
    "ft_mtx_cp[cf_mtx<confidence_lower_bound_amore]=0\n",
    "DT_ft_mtx_cp[DT_cf_mtx<confidence_lower_bound_dt]=0.\n",
    "for s in range(cf_mtx.shape[1]):\n",
    "    cid = np.argmax(ft_mtx_cp[:,s])\n",
    "    bc = cf_mtx[cid,s]\n",
    "    if bc >= confidence_lower_bound_amore:\n",
    "        best_cfs.append(bc)\n",
    "        best_fts.append(ft_mtx[cid,s])\n",
    "        best_ass.append(as_mtx[cid,s])\n",
    "    else:\n",
    "        cid = np.argmax(ft_mtx[:,s])\n",
    "        bc = cf_mtx[cid,s]\n",
    "        best_cfs.append(bc)\n",
    "        best_fts.append(ft_mtx[cid,s])\n",
    "        best_ass.append(as_mtx[cid,s])\n",
    "    cid = np.argmax(DT_ft_mtx_cp[:,s])\n",
    "    bc = DT_cf_mtx[cid,s]\n",
    "    if bc >= confidence_lower_bound_dt:\n",
    "        DT_best_cfs.append(bc)\n",
    "        DT_best_fts.append(DT_ft_mtx[cid,s])\n",
    "        DT_best_ass.append(DT_as_mtx[cid,s])\n",
    "    else:\n",
    "        cid = np.argmax(DT_ft_mtx[:,s])\n",
    "        bc = DT_cf_mtx[cid,s]\n",
    "        DT_best_cfs.append(bc)\n",
    "        DT_best_fts.append(DT_ft_mtx[cid,s])\n",
    "        DT_best_ass.append(DT_as_mtx[cid,s])\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(5,4))\n",
    "color1 = '#377EB8'  # Blue\n",
    "color2 = '#E41A1C'  # Red\n",
    "color3 = '#4DAF4A'  # green\n",
    "plt.plot(support_range,best_cfs,'-o',color=color1,markersize=4)\n",
    "plt.plot(support_range,best_fts,'--o',color=color1,markersize=4)\n",
    "plt.plot(support_range,DT_best_cfs,'-o',color=color2,markersize=4)\n",
    "plt.plot(support_range,DT_best_fts,'--o',color=color2,markersize=4)\n",
    "plt.xlim(100,1900)\n",
    "plt.ylim(0.,1.)\n",
    "# Creating custom lines for the color legend\n",
    "custom_lines_color = [Line2D([0], [0], color=color1, lw=4),\n",
    "                      Line2D([0], [0], color=color2, lw=4)]\n",
    "# Creating custom lines for the line style legend\n",
    "custom_lines_style = [Line2D([0], [0], color='grey', lw=2, linestyle='-'),\n",
    "                      Line2D([0], [0], color='grey', lw=2, linestyle='--')]\n",
    "plt.xticks(np.arange(100, 2000, 200))\n",
    "plt.xlabel('Specified minimum support')\n",
    "# plt.savefig('plot/compare_DT_ER-LBD.svg')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.23 Task ER-LBD; Rules extracted from AMORE and DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### search rules for target pattern: pred_y > y_thd  ###\n",
    "### we set the hyperparameters obtaind by above grid search step ###\n",
    "\n",
    "min_support=best_configs['min_support']\n",
    "bin_strategy=best_configs['bin_strategy']\n",
    "num_grids=best_configs['num_grids']\n",
    "max_depth=2\n",
    "top_K=3\n",
    "\n",
    "y_rule_candidates = rlm.gen_rule_list_for_one_target(train_data_x.numpy()[idx],fids,y_pred_s>y_thd,y=y_true,c=1,sort_by=\"fitness\",\n",
    "                                                    min_support=min_support,num_grids=num_grids,max_depth=max_depth,top_K=top_K,\n",
    "                                                    local_x=None,feature_types=feature_types,bin_strategy=bin_strategy,\n",
    "                                                    verbose=False)\n",
    "\n",
    "for i, rules in enumerate(y_rule_candidates):   \n",
    "    rules[\"rules\"] = rlm.replace_feature_names(rules[\"rules\"],descriptors)\n",
    "    y_rule_candidates[i] = rules\n",
    "y_rule_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain rules for target pattern: pred_y > y_thd from a DecisionTreeClassifier ###\n",
    "### We set the hyperparameters obtaind by above grid search step ###\n",
    "criterion = DT_best_configs['criterion']\n",
    "class_weight = DT_best_configs['class_weight']\n",
    "min_support = DT_best_configs['min_support']\n",
    "\n",
    "\n",
    "input_feature_names =descriptors\n",
    "treemodel = DecisionTreeClassifier(max_depth=max_depth,min_samples_leaf=min_support,criterion=criterion,random_state=seed,class_weight=class_weight)\n",
    "treemodel.fit(train_data_x.numpy()[idx],y_pred_s>y_thd)\n",
    "rule_list, rule_value_list, rule_metric_list, new_lines = dtr.obtain_rule_lists_from_DT(treemodel,train_data_x.numpy()[idx],y_true,y_pred_s>y_thd,np.arange(train_data_x.numpy()[idx].shape[-1]),descriptors,c=1)\n",
    "print(export_text(treemodel))\n",
    "\n",
    "## display rules extracted by DT classifier\n",
    "dtr.display_rules_from_DT(rule_list,rule_metric_list,input_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_molecules",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
