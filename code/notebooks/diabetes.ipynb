{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad55ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "# here = os.getcwd()\n",
    "# sys.path.append(os.path.join(here,\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cf7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,confusion_matrix,precision_score,recall_score,accuracy_score,roc_auc_score,roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import plot_tree,export_text,export_graphviz\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fcb161",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_results_filenames\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexplainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFPGrowth_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexplainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrule_pattern_miner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils.test_utils import make_results_filenames\n",
    "\n",
    "from explainer.FPGrowth_tree import *\n",
    "from explainer.rule_pattern_miner import *\n",
    "from explainer.explainer_utils import *\n",
    "import explainer.RuleGrowth_tree as rgtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33093e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3adde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_one_hot(df,col_name):\n",
    "    df[col_name] = pd.Categorical(df[col_name])\n",
    "    one_hot = pd.get_dummies(df[col_name])\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    df = df.drop(col_name,axis=1)\n",
    "    return df\n",
    "\n",
    "def min_max_normalization(df,col_name,min_val=None,max_val=None):\n",
    "    if min_val is None:\n",
    "        min_val = df[col_name].min()\n",
    "    if max_val is None:\n",
    "        max_val = df[col_name].max()\n",
    "    df[col_name] = (df[col_name]-min_val)/(max_val-min_val)\n",
    "    return df\n",
    "\n",
    "def min_max_multicols(df,col_names,min_max_df=None):\n",
    "    if min_max_df is None:\n",
    "        min_max_df = pd.DataFrame(columns=col_names)\n",
    "        min_max_df.loc[\"min\"] = df.loc[:,min_max_df.columns].min(axis=0)\n",
    "        min_max_df.loc[\"max\"] = df.loc[:,min_max_df.columns].max(axis=0)\n",
    "    for cn in col_names:\n",
    "        df = min_max_normalization(df,cn,min_max_df.loc[\"min\",cn],min_max_df.loc[\"max\",cn])\n",
    "    return df, min_max_df\n",
    "\n",
    "def recover_feature_raw_value(fid,fval,featur_names,raw_min_max,ntype=\"min_max\"):\n",
    "    fn = featur_names[fid]\n",
    "    if ntype == \"min_max\":\n",
    "        if fn in raw_min_max.columns:\n",
    "            mx = raw_min_max.loc[:,fn].max()\n",
    "            mi = raw_min_max.loc[:,fn].min()\n",
    "            return fval*(mx-mi)+mi\n",
    "        return fval\n",
    "    else:\n",
    "        raise TypeError(\"Not yet supported type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896cf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## control random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "## set data path to load data\n",
    "pp = \"/Users/chenyu/github/NDE-Models-DigitalHealth/\"\n",
    "dpath = pp+\"data/processed/diabetes_prediction_dataset.csv\"\n",
    "\n",
    "## set results path to save results\n",
    "rpath = \"./results/\"\n",
    "name = os.path.join(rpath,'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb955000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read diabetes dataset\n",
    "df = pd.read_csv(dpath,header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9835b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform categorical feature to one-hot-encoder\n",
    "df = encode_one_hot(df,'gender')\n",
    "df = encode_one_hot(df,'smoking_history')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7187fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split training and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.drop('diabetes',axis=1),df['diabetes'],test_size=0.3,random_state=seed)\n",
    "\n",
    "## min-max normalize numerical features\n",
    "X_train,min_max = min_max_multicols(X_train,col_names=['age','bmi','HbA1c_level','blood_glucose_level'])\n",
    "X_test,_ = min_max_multicols(X_test,col_names=min_max.columns,min_max_df=min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b37bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply oversampling on training set \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversampler = SMOTE(random_state=seed)\n",
    "X_over, y_over = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ec21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train a logistic regression model and check performance on test set\n",
    "log_reg = LogisticRegression(max_iter=2000,multi_class='ovr',random_state=seed)\n",
    "log_reg.fit(X_over,y_over)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = log_reg.score(X_test,y_test)\n",
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "precision = precision_score(y_test,y_pred,average=None)\n",
    "recall = recall_score(y_test,y_pred,average=None)\n",
    "accuracy,confusion,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get baseline samples and test samples for computing impact scores of features\n",
    "\n",
    "baselines = gen_intgrad_baselines(X_over.values,y_over.values)\n",
    "subset = gen_balanced_subset(X_train.values,y_train.values,size_per_class=int(y_train.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute impact score matrix\n",
    "\n",
    "C=2\n",
    "baseline_output = log_reg.predict_proba(baselines)[:,1]\n",
    "subset_output,yshift,int_g = [],[],[]    \n",
    "cids = np.arange(C)\n",
    "for k in cids:    \n",
    "    subset_output.append(log_reg.predict_proba(subset[k])[:,1])\n",
    "    for kk in cids[cids!=k]:\n",
    "        yshift.append(subset_output[k]-baseline_output[kk])\n",
    "        int_g.append((subset[k]-baselines[kk])* log_reg.coef_)\n",
    "yshift = np.concatenate(yshift)\n",
    "int_g = np.vstack(int_g)\n",
    "y_int_g = np.abs(int_g)/yshift.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find threshold for impact score\n",
    "\n",
    "thds = np.linspace(0.01,1.,1000)\n",
    "f_n = []\n",
    "for thd in thds:\n",
    "    mask = np.abs(y_int_g) >= thd \n",
    "    f_n.append((thd,(mask.sum(axis=0)>=len(y_int_g)*0.99).sum()))\n",
    "#     print(f_n[-1])\n",
    "    if f_n[-1][1]==1:\n",
    "        break\n",
    "thd = f_n[-1][0]\n",
    "thd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e07c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plot the scanning process of finding threshold\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([th[0] for th in f_n[:]],[(th[1]) for th in f_n[:]])\n",
    "plt.plot(f_n[-1][0],(f_n[-1][1]),\"r*\",label=\"Selected impact threshold\")\n",
    "plt.plot([0,f_n[-1][0]],[(f_n[-1][1]),(f_n[-1][1])],\":r\")\n",
    "plt.plot([f_n[-1][0],f_n[-1][0]],[0,f_n[-1][1]],\":r\")\n",
    "plt.xlim(0.,.3)\n",
    "plt.ylim(0.,10)\n",
    "plt.yticks([0,1,2,4,6,8,10],fontsize=16,fontstyle='italic')\n",
    "plt.xticks(fontsize=16,fontstyle='italic')\n",
    "plt.xlabel(r\"Feature impact score threshod -- $\\mathbf{j}_{th}$\",fontsize=20)\n",
    "plt.ylabel(r\"Number of features with $\\gamma BM$ frequecy\",fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "# plt.savefig(\"./results/diabetes/score_thd.svg\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify frequent important feature set\n",
    "\n",
    "itemsets_y = transform_intgrad_to_itemsets(y_int_g,thd=thd,K=1)\n",
    "fids = gen_freq_feature_set(itemsets_y[0],min_support=500,max_len=100)\n",
    "fids = np.array(fids).astype(int)-1\n",
    "print('feature set',fids,len(fids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy as sp\n",
    "\n",
    "## find and plot the prediction threshold using ROC\n",
    "\n",
    "pred_y = log_reg.predict_proba(X_train)[:,1]\n",
    "auc = roc_auc_score(y_train, pred_y)\n",
    "print(\"auc\",auc)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, pred_y)\n",
    "th_id = np.argmax(tpr - fpr)\n",
    "y_thd = thresholds[th_id]\n",
    "print(\"y threshold\",y_thd)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot(fpr[th_id],tpr[th_id],\"r*\")\n",
    "plt.annotate('$y_{th}=$'+str(y_thd.round(3)), (fpr[th_id],tpr[th_id]), textcoords='offset points', xytext=(42,-8), ha='center',fontsize=14)\n",
    "\n",
    "plt.plot([fpr[th_id],fpr[th_id]],[0,tpr[th_id]],\"r:\")\n",
    "plt.plot([-0.02,fpr[th_id]],[tpr[th_id],tpr[th_id]],\"r:\")\n",
    "plt.xlim(-0.02,1.)\n",
    "plt.xticks([0.,fpr[th_id],0.2,0.4,0.6,0.8,1.])\n",
    "plt.yticks([0.,0.2,0.4,0.6,0.8,tpr[th_id],1.])\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlabel('False Positive Rate (FPR)',fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)',fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "# plt.savefig(\"./results/diabetes/roc.eps\",bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check AUC on test set\n",
    "pred_y_test = log_reg.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, pred_y_test)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23caf1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### search rules for target pattern: pred_y > y_thd  ###\n",
    "\n",
    "import explainer.rule_pattern_miner as rlm\n",
    "\n",
    "min_support=2500\n",
    "num_grids=20\n",
    "max_depth=1\n",
    "top_K=3\n",
    "\n",
    "y_rule_candidates = rlm.gen_rule_list_for_one_target(X_train.values,fids,pred_y>y_thd,y=y_train.values,c=1,sort_by=\"cond_prob_y\",\n",
    "                                                    min_support=min_support,num_grids=num_grids,max_depth=max_depth,top_K=top_K,\n",
    "                                                    local_x=None,feature_types=None,\n",
    "                                                    verbose=False)\n",
    "\n",
    "for i, rules in enumerate(y_rule_candidates):   \n",
    "    rules[\"rules\"] = rlm.replace_feature_names(rules[\"rules\"],X_train.columns)\n",
    "    y_rule_candidates[i] = rules\n",
    "y_rule_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c543005",
   "metadata": {},
   "outputs": [],
   "source": [
    "## recover raw feature value by reversing the min-max normalization\n",
    "\n",
    "for n in range(len(y_rule_candidates)):\n",
    "    for i, r in enumerate(y_rule_candidates[n][\"rules\"]):\n",
    "        nr = recover_feature_raw_value(r[0],r[-1],X_train.columns,min_max)\n",
    "        y_rule_candidates[n][\"rules\"][i] = (*r[:-1],nr) \n",
    "        print(y_rule_candidates[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import explainer.DT_rules as dtr\n",
    "from explainer.DT_rules import obtain_rule_lists_from_DT,select_rule_list\n",
    "\n",
    "### otain rules for target pattern: pred_y > y_thd from a DecisionTreeClassifier\n",
    "\n",
    "input_feature_names =X_train.columns\n",
    "treemodel = DecisionTreeClassifier(max_depth=max_depth,min_samples_leaf=min_support,random_state=seed)\n",
    "treemodel.fit(X_train,pred_y>y_thd)\n",
    "rule_list, rule_value_list, rule_metric_list, new_lines = dtr.obtain_rule_lists_from_DT(treemodel,5,X_train.values,y_train.values,pred_y>y_thd,np.arange(X_train.shape[-1]),X_train.columns,c=1)\n",
    "print(export_text(treemodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## recover raw feature value by reversing the min-max normalization\n",
    "for s in range(len(rule_list)):\n",
    "    for j, r in enumerate(rule_list[s]):\n",
    "        nr = recover_feature_raw_value(r[0],r[-1],X_train.columns,min_max)\n",
    "        rule_list[s][j] = (*r[:-1],nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display rules extracted by DT classifier\n",
    "dtr.display_rules_from_DT(rule_list,rule_metric_list,input_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16521b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e46235",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract local rules for specific test samples\n",
    "\n",
    "## tids of test samples demonstrated in the paper: 4,15,144\n",
    "\n",
    "tid = 4 \n",
    "x = X_train.values\n",
    "xi = X_test.values[tid,:]\n",
    "pred_y_test[tid],y_test.values[tid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2dd7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_rules = rlm.gen_rule_list_for_one_target(X_train.values,fids,pred_y>y_thd,y=y_train.values,c=1,sort_by=\"fitness\",\n",
    "                                                            min_support=2000,num_grids=100,max_depth=3,top_K=3,\n",
    "                                                            local_x=xi,feature_types=None,search=\"greedy\",\n",
    "                                                            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the top local rule set\n",
    "\n",
    "rules = local_rules[0]\n",
    "rules[\"rules\"] = rlm.replace_feature_names(rules[\"rules\"],X_train.columns)\n",
    "for i, r in enumerate(rules[\"rules\"]):\n",
    "    nr = recover_feature_raw_value(r[0],r[-1],X_train.columns,min_max)\n",
    "    rules[\"rules\"][i] = (*r[:-1],nr) \n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83339ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
